{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85016f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\18643\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\18643\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\18643\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\18643\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#All the imports\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.models import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from sklearn import utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf06adc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Record run time for code to decide on size of data set to use for analysis\n",
    "StartTime = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e22b992",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading in two very different data frames: Luxury Beauty and Video Games\n",
    "#To help with intense computational requirements, limiting to approximately 100,000 reviews\n",
    "LuxuryBeautyDF = pd.read_json('Luxury_Beauty.json', lines=True) # Read in json file as a dataframe\n",
    "VideoGamesDF = pd.read_json('Video_Games_5.json', lines=True)\n",
    "Blend = [LuxuryBeautyDF,VideoGamesDF]\n",
    "BlendDF = pd.concat(Blend)\n",
    "BlendDF = BlendDF.sample(frac = 0.10).reset_index() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f300ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add column with Date from converted Unix time. Unfortunately results does not give time.\n",
    "BlendDF[\"Date\"] = pd.to_datetime(BlendDF[\"unixReviewTime\"], unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e86c131",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create binary rating column: 0 (negative = 1-2), 1 (positive = 3-5)\n",
    "#Binning decision came from running tests against validation data\n",
    "conditions = [\n",
    "    (BlendDF[\"overall\"] > 2),\n",
    "    (BlendDF[\"overall\"] < 3)\n",
    "    ]\n",
    "values = [1, 0]\n",
    "BlendDF['BinaryRating'] = np.select(conditions, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06d5d39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create column of review text with all lowercase, no punctuation, and no stopwords\n",
    "nan_value = float(\"NaN\") #Create na variable for blanks\n",
    "BlendDF[\"reviewText\"].replace(\"\", nan_value, inplace=True) #Replace blanks with na variable\n",
    "BlendDF.dropna(subset = [\"reviewText\"], inplace=True) #Drop all rows with na review text\n",
    "BlendDF[\"ReviewNoFiller\"] = BlendDF[\"reviewText\"].str.replace('[^\\w\\s]','',regex=True) #Create column with review text with no punctuation\n",
    "BlendDF[\"ReviewNoFiller\"] = BlendDF[\"ReviewNoFiller\"].str.lower() #Make all words lowercase\n",
    "stopwords = stopwords.words('english') #Create stopwords variable\n",
    "BlendDF[\"ReviewNoFiller\"] = BlendDF[\"ReviewNoFiller\"].apply(lambda x: ' '.join([word for word in x.split() if word not in (stopwords)])) #Remove stop words\n",
    "BlendDF[\"ReviewNoFiller\"].replace(\"\", nan_value, inplace=True,regex=True) #Replace blanks with na\n",
    "BlendDF.dropna(subset = [\"ReviewNoFiller\"], inplace=True) #Drop all rows with na review text, reset indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5a326eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Insert columns with tokenized review and summary\n",
    "BlendDF[\"ReviewToken\"] = BlendDF.apply(lambda row: word_tokenize(row[\"ReviewNoFiller\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d93aefb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lemmatize all reviews and summaries, rejoin the strings\n",
    "WNL = WordNetLemmatizer()\n",
    "def lemmatize_text(text):\n",
    "    return [WNL.lemmatize(w) for w in text]\n",
    "BlendDF['ReviewToken'] = BlendDF.ReviewToken.apply(lemmatize_text)\n",
    "BlendDF['ReviewLemma'] = BlendDF['ReviewToken'].apply(' '.join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0731140f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5    67860\n",
      "4    16423\n",
      "3     9094\n",
      "1     8187\n",
      "2     5461\n",
      "Name: overall, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Print out distribution of resulting review ratings\n",
    "print(BlendDF['overall'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "987d03cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Insert column with VADER sentiment analysis compound score of full review text, scale numbers from 1 to 5\n",
    "vader = SentimentIntensityAnalyzer()\n",
    "BlendDF[\"VaderCompound\"] = [vader.polarity_scores(x)['compound'] for x in BlendDF[\"reviewText\"]]\n",
    "scaler = MinMaxScaler(feature_range=(1,5))\n",
    "BlendDF[\"VaderCompound\"] = scaler.fit_transform(BlendDF[\"VaderCompound\"].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a9adb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Insert column with review word count\n",
    "BlendDF[\"WordCount\"] = BlendDF[\"ReviewToken\"].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78cfd107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    107025.000000\n",
      "mean         40.495576\n",
      "std          85.749642\n",
      "min           1.000000\n",
      "25%           6.000000\n",
      "50%          15.000000\n",
      "75%          38.000000\n",
      "max        2975.000000\n",
      "Name: WordCount, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#What does word count distribution look like? Need visualization to decide how to bin data. Also look at descriptive statistics.\n",
    "WordHist = BlendDF.hist(column = 'WordCount', bins=300)\n",
    "plt.xlim([0,150])\n",
    "print(BlendDF[\"WordCount\"].describe()) #25% is 6 or less, 25% is 29 words or more, will bin accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb48f5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create column categorizing review word count as short (1) or not (0)\n",
    "conditions = [\n",
    "    (BlendDF[\"WordCount\"] < 7),\n",
    "    (BlendDF[\"WordCount\"] > 6)\n",
    "    ]\n",
    "values = [1,0]\n",
    "BlendDF['Short'] = np.select(conditions, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31aa1461",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create column categorizing review word count as long (1) or not (0)\n",
    "conditions = [\n",
    "    (BlendDF[\"WordCount\"] > 28),\n",
    "    (BlendDF[\"WordCount\"] < 29)\n",
    "    ]\n",
    "values = [1,0]\n",
    "BlendDF['Long'] = np.select(conditions, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4fa7d1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create column categorizing reviewer as verified (1) or not (0)\n",
    "conditions = [\n",
    "    (BlendDF['verified'] == True),\n",
    "    (BlendDF['verified'] == False)\n",
    "    ]\n",
    "values = [1, 0]\n",
    "BlendDF['Verified'] = np.select(conditions, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a33de467",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create binary column if the reviewer uploaded an image (1) or did not (0)\n",
    "conditions = [\n",
    "    (pd.notnull(BlendDF['image'])),\n",
    "    (pd.isnull(BlendDF['image']))\n",
    "    ]\n",
    "values = [1, 0]\n",
    "BlendDF['IsImage'] = np.select(conditions, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a53b258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index                      int64\n",
      "overall                    int64\n",
      "vote                      object\n",
      "verified                    bool\n",
      "reviewTime                object\n",
      "reviewerID                object\n",
      "asin                      object\n",
      "reviewerName              object\n",
      "reviewText                object\n",
      "summary                   object\n",
      "unixReviewTime             int64\n",
      "style                     object\n",
      "image                     object\n",
      "Date              datetime64[ns]\n",
      "BinaryRating               int32\n",
      "ReviewNoFiller            object\n",
      "ReviewToken               object\n",
      "ReviewLemma               object\n",
      "VaderCompound            float64\n",
      "WordCount                  int64\n",
      "Short                      int32\n",
      "Long                       int32\n",
      "Verified                   int32\n",
      "IsImage                    int32\n",
      "dtype: object \n",
      "\n",
      "index                      int64\n",
      "overall                    int64\n",
      "vote                       int32\n",
      "verified                    bool\n",
      "reviewTime                object\n",
      "reviewerID                object\n",
      "asin                      object\n",
      "reviewerName              object\n",
      "reviewText                object\n",
      "summary                   object\n",
      "unixReviewTime             int64\n",
      "style                     object\n",
      "image                     object\n",
      "Date              datetime64[ns]\n",
      "BinaryRating               int32\n",
      "ReviewNoFiller            object\n",
      "ReviewToken               object\n",
      "ReviewLemma               object\n",
      "VaderCompound            float64\n",
      "WordCount                  int64\n",
      "Short                      int32\n",
      "Long                       int32\n",
      "Verified                   int32\n",
      "IsImage                    int32\n",
      "dtype: object \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Adjust vote column to allow for analysis\n",
    "print(BlendDF.dtypes,'\\n')\n",
    "BlendDF['vote'] = BlendDF['vote'].str.replace('[^\\w\\s]','',regex=True) #Remove all punctuation from strings\n",
    "BlendDF['vote'].replace('', '0', inplace=True) #Replace blanks with 0\n",
    "BlendDF['vote'] = BlendDF['vote'].fillna('0') # Replace na values with 0\n",
    "BlendDF['vote'] = BlendDF['vote'].astype({'vote': 'int32'})\n",
    "print(BlendDF.dtypes,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8dc3a57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read into five emotions lexicon, convert into five dictionaries\n",
    "WarrinerWords = pd.read_csv(\"Warriner_BE.txt\", sep='\\t')\n",
    "JoyDict = dict(zip(WarrinerWords.Word, WarrinerWords.Joy))\n",
    "AngerDict = dict(zip(WarrinerWords.Word, WarrinerWords.Anger))\n",
    "SadnessDict = dict(zip(WarrinerWords.Word, WarrinerWords.Sadness))\n",
    "FearDict = dict(zip(WarrinerWords.Word, WarrinerWords.Fear))\n",
    "DisgustDict = dict(zip(WarrinerWords.Word, WarrinerWords.Disgust))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a750a7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create columns for five emotions, initialize all of them at zero\n",
    "BlendDF['Joy'] = 0.0\n",
    "BlendDF['Anger'] = 0.0\n",
    "BlendDF['Sadness'] = 0.0\n",
    "BlendDF['Fear'] = 0.0\n",
    "BlendDF['Disgust'] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6354b54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iterate through all lists of words, assigning them scores for all emotions\n",
    "for index, row in BlendDF.iterrows():\n",
    "    for word in row['ReviewToken']:\n",
    "        BlendDF.at[index,'Joy'] += JoyDict.get(word,0)\n",
    "        BlendDF.at[index,'Anger'] += AngerDict.get(word,0)\n",
    "        BlendDF.at[index,'Sadness'] += SadnessDict.get(word,0)\n",
    "        BlendDF.at[index,'Fear'] += FearDict.get(word,0)\n",
    "        BlendDF.at[index,'Disgust'] += DisgustDict.get(word,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3d61dbe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReviewLemma\n",
      "VaderCompound\n",
      "Short\n",
      "Verified\n",
      "Long\n",
      "IsImage\n",
      "WordCount\n",
      "vote\n",
      "Joy\n",
      "Anger\n",
      "Sadness\n",
      "Fear\n",
      "Disgust\n",
      "overall\n",
      "BinaryRating\n",
      "                                         ReviewLemma  VaderCompound  Short  \\\n",
      "0  tiny tube much money smelled good 6 time able ...       3.880888      0   \n",
      "1  hand one best entry series first time since ru...       4.880188      0   \n",
      "2                                      great product       4.249925      1   \n",
      "3                                         great game       4.249925      1   \n",
      "4  good product good consistency fast shipping se...       4.452945      0   \n",
      "\n",
      "   Verified  Long  IsImage  WordCount  vote      Joy    Anger  Sadness  \\\n",
      "0         0     0        0         11     2  19.0114   9.2388   9.1739   \n",
      "1         1     0        0         28     0  50.9765  24.3794  23.8156   \n",
      "2         1     0        0          2     0   5.6550   2.4657   2.5097   \n",
      "3         1     0        0          2     0   7.2150   2.5111   2.6126   \n",
      "4         1     0        0          7     0  16.2300   7.7435   7.8191   \n",
      "\n",
      "      Fear  Disgust  overall  BinaryRating  \n",
      "0   9.6452   8.9947        1             0  \n",
      "1  24.4752  25.6067        5             1  \n",
      "2   2.5197   2.4247        5             1  \n",
      "3   2.6371   2.4150        5             1  \n",
      "4   7.9723   7.4905        5             1  \n",
      "The number of rows in the data frame is: 107025\n"
     ]
    }
   ],
   "source": [
    "#Create data frame for analysis\n",
    "BlendDF = BlendDF[['ReviewLemma','VaderCompound','Short','Verified','Long','IsImage','WordCount','vote','Joy','Anger','Sadness','Fear','Disgust','overall','BinaryRating']]\n",
    "\n",
    "#Print some of the dataframe to verify work\n",
    "pd.set_option('display.max_columns', None) #So as not to truncate output\n",
    "pd.set_option('display.max_rows', None) #So as not to truncate output\n",
    "for col in BlendDF.columns: #Print column names\n",
    "    print(col)\n",
    "print(BlendDF.head()) # Print first five entries in dataframe\n",
    "print(\"The number of rows in the data frame is:\", len(BlendDF.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "38316796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write final dataframe into csv\n",
    "BlendDF.to_csv(r'BlendedReviews.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9b90375b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Linear SVC Model Score for TFIDF is: 89.32 % \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.65      0.61      2716\n",
      "           1       0.95      0.93      0.94     18689\n",
      "\n",
      "    accuracy                           0.89     21405\n",
      "   macro avg       0.76      0.79      0.77     21405\n",
      "weighted avg       0.90      0.89      0.90     21405\n",
      " \n",
      "\n",
      "Multiclass Linear SVC Model Score for TFIDF is: 64.1 % \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.53      0.52      1615\n",
      "           2       0.22      0.20      0.21      1101\n",
      "           3       0.28      0.30      0.29      1842\n",
      "           4       0.32      0.33      0.32      3264\n",
      "           5       0.82      0.81      0.82     13583\n",
      "\n",
      "    accuracy                           0.64     21405\n",
      "   macro avg       0.43      0.43      0.43     21405\n",
      "weighted avg       0.64      0.64      0.64     21405\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "TF-IDF Approach\n",
    "\"\"\"\n",
    "\n",
    "#Implement TF-IDF for binary model\n",
    "tfidf = TfidfVectorizer(max_features=100000, ngram_range=(1,7), analyzer='char')\n",
    "X = tfidf.fit_transform(BlendDF['ReviewLemma'])\n",
    "Y = BlendDF['BinaryRating']\n",
    "X.shape, Y.shape\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=1) #Split into 80/20 train and test sets\n",
    "\n",
    "#Implement Linear SVC model for binary TF-IDF\n",
    "#89.55% Accuracy for 10% of data, 89.09% for 25% of data\n",
    "LSVC = LinearSVC(C = 10, class_weight='balanced', max_iter=10000)\n",
    "LSVC.fit(X_train, Y_train)\n",
    "LSVCScore = round((LSVC.score(X_test, Y_test))*100,2)\n",
    "print('Binary Linear SVC Model Score for TFIDF is:',LSVCScore,'%', '\\n')\n",
    "Y_pred = LSVC.predict(X_test)\n",
    "print(classification_report(Y_test, Y_pred, zero_division=0), '\\n')\n",
    "\n",
    "#Implement TF-IDF for multiclass model\n",
    "tfidf = TfidfVectorizer(max_features=100000, ngram_range=(1,7), analyzer='char')\n",
    "X = tfidf.fit_transform(BlendDF['ReviewLemma'])\n",
    "Y = BlendDF['overall']\n",
    "X.shape, Y.shape\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=1) #Split into 80/20 train and test sets\n",
    "\n",
    "#Implement Linear SVC model for TF-IDF multiclass\n",
    "#63.98% Accuracy for 10% of data, 64.98% for 25% of data\n",
    "LSVC = LinearSVC(C = 10, class_weight='balanced', max_iter=10000)\n",
    "LSVC.fit(X_train, Y_train)\n",
    "LSVCScore = round((LSVC.score(X_test, Y_test))*100,2)\n",
    "print('Multiclass Linear SVC Model Score for TFIDF is:',LSVCScore,'%', '\\n')\n",
    "Y_pred = LSVC.predict(X_test)\n",
    "print(classification_report(Y_test, Y_pred, zero_division=0), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c14be7c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\18643\\AppData\\Local\\Temp/ipykernel_17660/1973115851.py:38: DeprecationWarning: Call to deprecated `docvecs` (The `docvecs` property has been renamed `dv`.).\n",
      "  vectors[i] = model.docvecs[prefix]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Logistic Model Score for Doc2Vec: 90.16 % \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.42      0.52      2716\n",
      "           1       0.92      0.97      0.95     18689\n",
      "\n",
      "    accuracy                           0.90     21405\n",
      "   macro avg       0.80      0.70      0.73     21405\n",
      "weighted avg       0.89      0.90      0.89     21405\n",
      " \n",
      "\n",
      "Binary Linear SVC Model Score for Doc2Vec is: 82.7 % \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.79      0.54      2716\n",
      "           1       0.97      0.83      0.89     18689\n",
      "\n",
      "    accuracy                           0.83     21405\n",
      "   macro avg       0.69      0.81      0.72     21405\n",
      "weighted avg       0.89      0.83      0.85     21405\n",
      " \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Doc2Vec Approach\n",
    "First group of models are binary models predicting positive or negative rating\n",
    "\"\"\"\n",
    "\n",
    "#Split into 80/20 train and test \n",
    "X = BlendDF['ReviewLemma']\n",
    "Y = BlendDF['BinaryRating']\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=1)\n",
    "\n",
    "#Function to label reviews train or test\n",
    "def label_reviews(review, label_type):\n",
    "    labeled = []\n",
    "    for i,v in enumerate(review):\n",
    "        label = label_type + '_' + str(i)\n",
    "        labeled.append(TaggedDocument(v.split(), [label]))\n",
    "    return labeled\n",
    "\n",
    "#Label training and test sets using function\n",
    "X_train = label_reviews(X_train, 'Train')\n",
    "X_test = label_reviews(X_test,'Test')\n",
    "AllData = X_train + X_test\n",
    "\n",
    "#Build BOW Doc2Vec model\n",
    "DBOWModel = Doc2Vec(dm=0, vector_size=300, negative=5, min_count=1, alpha=0.065, min_alpha=0.065)\n",
    "DBOWModel.build_vocab([x for x in AllData])\n",
    "\n",
    "#Iterate over data to train model\n",
    "for epoch in range(30):\n",
    "    DBOWModel.train(utils.shuffle([x for x in AllData]), total_examples=len(AllData), epochs=1)\n",
    "    DBOWModel.alpha -= 0.002\n",
    "    DBOWModel.min_alpha = DBOWModel.alpha\n",
    "\n",
    "#Create function to vectorize all reviews\n",
    "def get_vectors(model, corpus_size, vectors_size, vectors_type):\n",
    "    vectors = np.zeros((corpus_size, vectors_size))\n",
    "    for i in range(0, corpus_size):\n",
    "        prefix = vectors_type + '_' + str(i)\n",
    "        vectors[i] = model.docvecs[prefix]\n",
    "    return vectors\n",
    "\n",
    "#Vectorize training and testing data\n",
    "train_vectors_dbow = get_vectors(DBOWModel, len(X_train), 300, 'Train')\n",
    "test_vectors_dbow = get_vectors(DBOWModel, len(X_test), 300, 'Test')\n",
    "\n",
    "#Run binary logistic regression\n",
    "LR = linear_model.LogisticRegression()\n",
    "LR = LR.fit(train_vectors_dbow, Y_train)\n",
    "\n",
    "#Look at ability of model to predict test set\n",
    "#90.16% Accuracy\n",
    "LRScore = round((LR.score(test_vectors_dbow, Y_test))*100,2)\n",
    "print('Binary Logistic Model Score for Doc2Vec:',LRScore,'%','\\n')\n",
    "Y_pred = LR.predict(test_vectors_dbow)\n",
    "print(classification_report(Y_test, Y_pred, zero_division=0), '\\n')\n",
    "\n",
    "#Implement Linear SVC model for binary Doc2Vec\n",
    "#82.7% Accuracy\n",
    "LSVC = LinearSVC(C = 10, class_weight='balanced', max_iter=10000)\n",
    "LSVC.fit(train_vectors_dbow, Y_train)\n",
    "LSVCScore = round((LSVC.score(test_vectors_dbow, Y_test))*100,2)\n",
    "print('Binary Linear SVC Model Score for Doc2Vec is:',LSVCScore,'%', '\\n')\n",
    "Y_pred = LSVC.predict(test_vectors_dbow)\n",
    "print(classification_report(Y_test, Y_pred, zero_division=0), '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f2266cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\18643\\AppData\\Local\\Temp/ipykernel_17660/1973115851.py:38: DeprecationWarning: Call to deprecated `docvecs` (The `docvecs` property has been renamed `dv`.).\n",
      "  vectors[i] = model.docvecs[prefix]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Logistic Model Score for Doc2Vec:  68.54 % \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.51      0.52      1615\n",
      "           2       0.29      0.09      0.13      1101\n",
      "           3       0.36      0.20      0.25      1842\n",
      "           4       0.44      0.20      0.28      3264\n",
      "           5       0.75      0.94      0.83     13583\n",
      "\n",
      "    accuracy                           0.69     21405\n",
      "   macro avg       0.47      0.39      0.40     21405\n",
      "weighted avg       0.63      0.69      0.64     21405\n",
      " \n",
      "\n",
      "Multiclass Linear SVC Model Score for Doc2Vec is: 65.91 % \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.43      0.65      0.52      1615\n",
      "           2       0.21      0.17      0.19      1101\n",
      "           3       0.30      0.28      0.29      1842\n",
      "           4       0.39      0.24      0.30      3264\n",
      "           5       0.81      0.85      0.83     13583\n",
      "\n",
      "    accuracy                           0.66     21405\n",
      "   macro avg       0.43      0.44      0.42     21405\n",
      "weighted avg       0.64      0.66      0.65     21405\n",
      " \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Doc2Vec Approach\n",
    "Second group of models are multiclass models for 1-5 rating\n",
    "\"\"\"\n",
    "\n",
    "#Split into 80/20 train and test \n",
    "X = BlendDF['ReviewLemma']\n",
    "Y = BlendDF['overall']\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=1)\n",
    "\n",
    "#Label training and test sets using function\n",
    "X_train = label_reviews(X_train, 'Train')\n",
    "X_test = label_reviews(X_test,'Test')\n",
    "AllData = X_train + X_test\n",
    "\n",
    "#Build Doc2Vec model\n",
    "DBOWModel = Doc2Vec(dm=0, vector_size=300, negative=5, min_count=1, alpha=0.065, min_alpha=0.065)\n",
    "DBOWModel.build_vocab([x for x in AllData])\n",
    "\n",
    "#Iterate over data to train model\n",
    "for epoch in range(30):\n",
    "    DBOWModel.train(utils.shuffle([x for x in AllData]), total_examples=len(AllData), epochs=1)\n",
    "    DBOWModel.alpha -= 0.002\n",
    "    DBOWModel.min_alpha = DBOWModel.alpha\n",
    "\n",
    "#Vectorize training and testing data\n",
    "train_vectors_dbow = get_vectors(DBOWModel, len(X_train), 300, 'Train')\n",
    "test_vectors_dbow = get_vectors(DBOWModel, len(X_test), 300, 'Test')\n",
    "\n",
    "#Run multinomial logistic regression\n",
    "MLR = linear_model.LogisticRegression(multi_class='multinomial', solver='lbfgs',max_iter=10000)\n",
    "MLR.fit(train_vectors_dbow, Y_train)\n",
    "\n",
    "#Look at ability of model to predict test set\n",
    "#68.54% Accuracy\n",
    "MLRScore = round((MLR.score(test_vectors_dbow, Y_test))*100,2)\n",
    "print('Multinomial Logistic Model Score for Doc2Vec: ',MLRScore,'%','\\n')\n",
    "Y_pred = MLR.predict(test_vectors_dbow)\n",
    "print(classification_report(Y_test, Y_pred, zero_division=0), '\\n')\n",
    "\n",
    "#Implement Linear SVC model for multiclass Doc2Vec\n",
    "#65.91% Accuracy\n",
    "LSVC = LinearSVC(C = 10, class_weight='balanced', max_iter=10000)\n",
    "LSVC.fit(train_vectors_dbow, Y_train)\n",
    "LSVCScore = round((LSVC.score(test_vectors_dbow, Y_test))*100,2)\n",
    "print('Multiclass Linear SVC Model Score for Doc2Vec is:',LSVCScore,'%', '\\n')\n",
    "Y_pred = LSVC.predict(test_vectors_dbow)\n",
    "print(classification_report(Y_test, Y_pred, zero_division=0), '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "36fb7069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Logistic Intercept is: [-2.25425174] \n",
      "\n",
      "Binary Logistic Coefficients are: [[ 1.0505155   0.69373129  0.20574623 -0.18606265 -0.91405258]] \n",
      "\n",
      "Binary Logistic Model Score for VADER Score and other variables: 87.52 % \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.25      0.33      2716\n",
      "           1       0.90      0.97      0.93     18689\n",
      "\n",
      "    accuracy                           0.88     21405\n",
      "   macro avg       0.71      0.61      0.63     21405\n",
      "weighted avg       0.85      0.88      0.86     21405\n",
      " \n",
      "\n",
      "Binary SVM Score for VADER Score and other variables: 87.31 % \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      2716\n",
      "           1       0.87      1.00      0.93     18689\n",
      "\n",
      "    accuracy                           0.87     21405\n",
      "   macro avg       0.44      0.50      0.47     21405\n",
      "weighted avg       0.76      0.87      0.81     21405\n",
      " \n",
      "\n",
      "Binary Naive Bayes Classifier Score for VADER Score and other variables: 86.9 % \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.32      0.38      2716\n",
      "           1       0.91      0.95      0.93     18689\n",
      "\n",
      "    accuracy                           0.87     21405\n",
      "   macro avg       0.69      0.63      0.65     21405\n",
      "weighted avg       0.85      0.87      0.86     21405\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "VADER Score and other variables approach\n",
    "First group of models are binary models predicting positive or negative rating\n",
    "\"\"\"\n",
    "\n",
    "#Split data into training and test sets with a 80/20 split for all binary models\n",
    "#Based on the very low coefficients for both WordCount and vote, these variables were left out of the models.\n",
    "X = BlendDF[['VaderCompound','Short','Verified','Long','IsImage']] #set independent variables for regression\n",
    "Y = BlendDF['BinaryRating'] #set dependent variable for regression\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=1) #Split into 80/20 train and test sets\n",
    "\n",
    "#Run binary logistic regression\n",
    "LR = linear_model.LogisticRegression()\n",
    "LR.fit(X_train, Y_train)\n",
    "print('Binary Logistic Intercept is:', LR.intercept_, '\\n')\n",
    "print('Binary Logistic Coefficients are:', LR.coef_, '\\n')\n",
    "\n",
    "#Look at ability of model to predict test set\n",
    "#87.97% Accuracy for 10% of data, 88.14% for 25% of data\n",
    "LRScore = round((LR.score(X_test, Y_test))*100,2)\n",
    "print('Binary Logistic Model Score for VADER Score and other variables:',LRScore,'%','\\n')\n",
    "Y_pred = LR.predict(X_test)\n",
    "print(classification_report(Y_test, Y_pred, zero_division=0), '\\n')\n",
    "\n",
    "#Run Binary SVM\n",
    "svclassifier = SVC(kernel='linear')\n",
    "svclassifier.fit(X_train, Y_train)\n",
    "\n",
    "#Look at ability of model to predict test set\n",
    "#87.67% Accuracy for 10% of data, 87.6% for 25% of data\n",
    "SVMScore = round((svclassifier.score(X_test, Y_test))*100,2)\n",
    "print('Binary SVM Score for VADER Score and other variables:',SVMScore,'%','\\n')\n",
    "Y_pred = svclassifier.predict(X_test)\n",
    "print(classification_report(Y_test, Y_pred, zero_division=0), '\\n')\n",
    "\n",
    "#Run Naive Bayes Classifier\n",
    "NB = GaussianNB()\n",
    "NB.fit(X_train, Y_train)\n",
    "\n",
    "#Look at ability of model to predict test set\n",
    "#87.28% Accuracy with 10% of data, 87.54% with 25% of data\n",
    "NBScore = round((NB.score(X_test, Y_test))*100,2)\n",
    "print('Binary Naive Bayes Classifier Score for VADER Score and other variables:',NBScore,'%','\\n')\n",
    "Y_pred = NB.predict(X_test)\n",
    "print(classification_report(Y_test, Y_pred, zero_division=0), '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9a4e44ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Logistic Model Score for VADER Score and other variables:  64.57 % \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.33      0.38      0.35      1615\n",
      "           2       0.00      0.00      0.00      1101\n",
      "           3       0.17      0.01      0.01      1842\n",
      "           4       0.15      0.00      0.01      3264\n",
      "           5       0.68      0.97      0.80     13583\n",
      "\n",
      "    accuracy                           0.65     21405\n",
      "   macro avg       0.27      0.27      0.23     21405\n",
      "weighted avg       0.49      0.65      0.54     21405\n",
      " \n",
      "\n",
      "Multiclass SVM Score is for VADER Score and other variables:  64.66 % \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.34      0.35      0.34      1615\n",
      "           2       0.00      0.00      0.00      1101\n",
      "           3       0.00      0.00      0.00      1842\n",
      "           4       0.00      0.00      0.00      3264\n",
      "           5       0.67      0.98      0.80     13583\n",
      "\n",
      "    accuracy                           0.65     21405\n",
      "   macro avg       0.20      0.26      0.23     21405\n",
      "weighted avg       0.45      0.65      0.53     21405\n",
      " \n",
      "\n",
      "K Nearest Neighbors Algorithm Model Score for VADER Score and other variables:  63.61 % \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.35      0.36      0.35      1615\n",
      "           2       0.20      0.05      0.08      1101\n",
      "           3       0.21      0.06      0.10      1842\n",
      "           4       0.26      0.07      0.11      3264\n",
      "           5       0.70      0.93      0.80     13583\n",
      "\n",
      "    accuracy                           0.64     21405\n",
      "   macro avg       0.34      0.30      0.29     21405\n",
      "weighted avg       0.54      0.64      0.56     21405\n",
      " \n",
      "\n",
      "Random Forest Classifier Model Score for VADER Score and other variables:  60.76 % \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.31      0.27      0.29      1615\n",
      "           2       0.17      0.09      0.12      1101\n",
      "           3       0.20      0.12      0.15      1842\n",
      "           4       0.23      0.11      0.15      3264\n",
      "           5       0.71      0.88      0.78     13583\n",
      "\n",
      "    accuracy                           0.61     21405\n",
      "   macro avg       0.32      0.29      0.30     21405\n",
      "weighted avg       0.53      0.61      0.56     21405\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "VADER Score and other variables approach\n",
    "Second group of models are multiclass models for 1-5 rating\n",
    "\"\"\"\n",
    "#Split data into training and test sets with a 80/20 split for multiclass models\n",
    "X = BlendDF[['VaderCompound','Short','Verified','Long','IsImage']] #set independent variables for regression\n",
    "Y = BlendDF['overall'] #set dependent variable for regression\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=1) #Split into 80/20 train and test sets\n",
    "\n",
    "#Run multinomial logistic regression\n",
    "MLR = linear_model.LogisticRegression(multi_class='multinomial', solver='lbfgs',max_iter=10000)\n",
    "MLR.fit(X_train, Y_train)\n",
    "\n",
    "#Look at ability of model to predict test set\n",
    "#64.86% Accuracy with 10% of data, 65.04% with 25% of data\n",
    "MLRScore = round((MLR.score(X_test, Y_test))*100,2)\n",
    "print('Multinomial Logistic Model Score for VADER Score and other variables: ',MLRScore,'%','\\n')\n",
    "Y_pred = MLR.predict(X_test)\n",
    "print(classification_report(Y_test, Y_pred, zero_division=0), '\\n')\n",
    "\n",
    "#Run Multiclass SVM\n",
    "msvclassifier = SVC(kernel='linear')\n",
    "msvclassifier.fit(X_train, Y_train)\n",
    "\n",
    "#Look at ability of model to predict test set\n",
    "#64.79% Accuracy with 10% of data, 64.97% with 25% of data\n",
    "MSVMScore = round((msvclassifier.score(X_test, Y_test))*100,2)\n",
    "print('Multiclass SVM Score is for VADER Score and other variables: ',MSVMScore,'%','\\n')\n",
    "Y_pred = msvclassifier.predict(X_test)\n",
    "print(classification_report(Y_test, Y_pred, zero_division=0), '\\n')\n",
    "\n",
    "#Run K Nearest Neighbors Algorithm\n",
    "KNN = KNeighborsClassifier(n_neighbors = 15)\n",
    "KNN.fit(X_train, Y_train)\n",
    "\n",
    "#Look at ability of model to predict test set\n",
    "#63.37% Accuracy with 10% of data, 63.23% with 25% of data\n",
    "KNNScore = round((KNN.score(X_test, Y_test))*100,2)\n",
    "print('K Nearest Neighbors Algorithm Model Score for VADER Score and other variables: ',KNNScore,'%','\\n')\n",
    "Y_pred = KNN.predict(X_test)\n",
    "print(classification_report(Y_test, Y_pred, zero_division=0), '\\n')\n",
    "\n",
    "#Run Random Forest Algorithm\n",
    "RF = RandomForestClassifier(n_estimators=5, random_state=0)\n",
    "RF.fit(X_train, Y_train)\n",
    "\n",
    "#Look at ability of model to predict test set\n",
    "#60.43% Accuracy with 10% of data, 62.73% with 25% of data\n",
    "RFScore = round((RF.score(X_test, Y_test))*100,2)\n",
    "print('Random Forest Classifier Model Score for VADER Score and other variables: ',RFScore,'%','\\n')\n",
    "Y_pred = RF.predict(X_test)\n",
    "print(classification_report(Y_test, Y_pred, zero_division=0), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "30d94258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Classifier Score is for Five Emotions Model:  87.31 % \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      2716\n",
      "           1       0.87      1.00      0.93     18689\n",
      "\n",
      "    accuracy                           0.87     21405\n",
      "   macro avg       0.44      0.50      0.47     21405\n",
      "weighted avg       0.76      0.87      0.81     21405\n",
      " \n",
      "\n",
      "Binary Logistic Model Score for Five Emotions Model:  87.05 % \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.02      0.04      2716\n",
      "           1       0.87      0.99      0.93     18689\n",
      "\n",
      "    accuracy                           0.87     21405\n",
      "   macro avg       0.60      0.51      0.48     21405\n",
      "weighted avg       0.81      0.87      0.82     21405\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Five Emotions Approach\n",
    "First group of models are binary models predicting positive or negative rating\n",
    "SVM Models have been excluded due to high number of continuous variables makes processing power/time overwhelming\n",
    "\"\"\"\n",
    "\n",
    "#Split data into training and test sets with a 80/20 split for all binary models\n",
    "#Based on the very low coefficients for both WordCount and vote, these variables were left out of the models.\n",
    "X = BlendDF[['Joy','Anger','Sadness','Fear','Disgust']] #set independent variables for regression\n",
    "Y = BlendDF['BinaryRating'] #set dependent variable for regression\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=1) #Split into 80/20 train and test sets\n",
    "\n",
    "#Run Naive Bayes Classifier\n",
    "NB = GaussianNB()\n",
    "NB.fit(X_train, Y_train)\n",
    "\n",
    "#Look at ability of model to predict test set\n",
    "#87.67% Accuracy with 10% of data, 87.6% with 25% of data\n",
    "NBScore = round((NB.score(X_test, Y_test))*100,2)\n",
    "print('Naive Bayes Classifier Score is for Five Emotions Model: ',NBScore,'%','\\n')\n",
    "Y_pred = NB.predict(X_test)\n",
    "print(classification_report(Y_test, Y_pred, zero_division=0), '\\n')\n",
    "\n",
    "#Run binary logistic regression\n",
    "LR = linear_model.LogisticRegression()\n",
    "LR.fit(X_train, Y_train)\n",
    "\n",
    "#Look at ability of model to predict test set\n",
    "#87.45 % Accuracy with 10% of data, 87.38% with 25% of data\n",
    "LRScore = round((LR.score(X_test, Y_test))*100,2)\n",
    "print('Binary Logistic Model Score for Five Emotions Model: ',LRScore,'%','\\n')\n",
    "Y_pred = LR.predict(X_test)\n",
    "print(classification_report(Y_test, Y_pred, zero_division=0), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b3b86c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Logistic Model Score for Five Emotions Model:  63.37 % \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.23      0.04      0.06      1615\n",
      "           2       0.17      0.00      0.00      1101\n",
      "           3       0.24      0.01      0.02      1842\n",
      "           4       0.35      0.03      0.05      3264\n",
      "           5       0.64      0.99      0.78     13583\n",
      "\n",
      "    accuracy                           0.63     21405\n",
      "   macro avg       0.33      0.21      0.18     21405\n",
      "weighted avg       0.51      0.63      0.51     21405\n",
      " \n",
      "\n",
      "K Nearest Neighbors Algorithm Model Score for Five Emotions Model:  61.98 % \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.29      0.15      0.20      1615\n",
      "           2       0.13      0.02      0.03      1101\n",
      "           3       0.13      0.02      0.04      1842\n",
      "           4       0.27      0.08      0.12      3264\n",
      "           5       0.66      0.94      0.78     13583\n",
      "\n",
      "    accuracy                           0.62     21405\n",
      "   macro avg       0.30      0.24      0.23     21405\n",
      "weighted avg       0.50      0.62      0.53     21405\n",
      " \n",
      "\n",
      "Random Forest Classifier Model Score for Five Emotions Model:  54.6 % \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.22      0.21      0.22      1615\n",
      "           2       0.12      0.09      0.10      1101\n",
      "           3       0.14      0.10      0.12      1842\n",
      "           4       0.21      0.17      0.19      3264\n",
      "           5       0.69      0.77      0.73     13583\n",
      "\n",
      "    accuracy                           0.55     21405\n",
      "   macro avg       0.28      0.27      0.27     21405\n",
      "weighted avg       0.51      0.55      0.52     21405\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Five Emotions Approach\n",
    "Second group of models are multiclass models for 1-5 rating\n",
    "SVM Models have been excluded due to high number of continuous variables makes processing power/time overwhelming\n",
    "\"\"\"\n",
    "\n",
    "#Split data into training and test sets with a 80/20 split for multiclass models\n",
    "X = BlendDF[['Joy','Anger','Sadness','Fear','Disgust']] #set independent variables for regression\n",
    "Y = BlendDF['overall'] #set dependent variable for regression\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=1) #Split into 80/20 train and test sets\n",
    "\n",
    "#Run multinomial logistic regression\n",
    "MLR = linear_model.LogisticRegression(multi_class='multinomial', solver='lbfgs',max_iter=10000)\n",
    "MLR.fit(X_train, Y_train)\n",
    "\n",
    "#Look at ability of model to predict test set\n",
    "#63.62% Accuracy with 10% of data, 63.56% with 25% of data\n",
    "MLRScore = round((MLR.score(X_test, Y_test))*100,2)\n",
    "print('Multinomial Logistic Model Score for Five Emotions Model: ',MLRScore,'%','\\n')\n",
    "Y_pred = MLR.predict(X_test)\n",
    "print(classification_report(Y_test, Y_pred, zero_division=0), '\\n')\n",
    "\n",
    "#Run K Nearest Neighbors Algorithm\n",
    "KNN = KNeighborsClassifier(n_neighbors = 15)\n",
    "KNN.fit(X_train, Y_train)\n",
    "\n",
    "#Look at ability of model to predict test set\n",
    "#62.55% Accuracy with 10% of data, 62.21% with 25% of data\n",
    "KNNScore = round((KNN.score(X_test, Y_test))*100,2)\n",
    "print('K Nearest Neighbors Algorithm Model Score for Five Emotions Model: ',KNNScore,'%','\\n')\n",
    "Y_pred = KNN.predict(X_test)\n",
    "print(classification_report(Y_test, Y_pred, zero_division=0), '\\n')\n",
    "\n",
    "#Run Random Forest Algorithm\n",
    "RF = RandomForestClassifier(n_estimators=5, random_state=0)\n",
    "RF.fit(X_train, Y_train)\n",
    "\n",
    "#Look at ability of model to predict test set\n",
    "#55.39% Accuracy with 10% of data, 56.14% with 25% of data\n",
    "RFScore = round((RF.score(X_test, Y_test))*100,2)\n",
    "print('Random Forest Classifier Model Score for Five Emotions Model: ',RFScore,'%','\\n')\n",
    "Y_pred = RF.predict(X_test)\n",
    "print(classification_report(Y_test, Y_pred, zero_division=0), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "62a03bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:59:42\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Print out run times to decide how big of a data set to use\n",
    "Code run times: 25 minutes 13 seconds for 10% of data; 2 hours 58 minutes 5 seconds for 25% of data\n",
    "\"\"\"\n",
    "\n",
    "ElapsedSeconds = time.time() - StartTime\n",
    "def convert(seconds):\n",
    "    seconds = seconds % (24 * 3600)\n",
    "    hour = seconds // 3600\n",
    "    seconds %= 3600\n",
    "    minutes = seconds // 60\n",
    "    seconds %= 60\n",
    "\n",
    "    return \"%d:%02d:%02d\" % (hour, minutes, seconds)\n",
    "print(convert(ElapsedSeconds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
