{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85016f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\18643\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\18643\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\18643\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\18643\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#All the imports\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.models import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from sklearn import utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf06adc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Record run time for code to decide on size of data set to use for analysis\n",
    "StartTime = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e22b992",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in two very different data frames (Luxury Beauty and Video Games)\n",
    "LuxuryBeautyDF = pd.read_json('Luxury_Beauty.json', lines=True)\n",
    "VideoGamesDF = pd.read_json('Video_Games_5.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b6bca48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create binary category columns for Luxury Beauty and Video Games\n",
    "LuxuryBeautyDF['LuxBea'] = 1\n",
    "LuxuryBeautyDF['VidGam'] = 0\n",
    "VideoGamesDF['LuxBea'] = 0\n",
    "VideoGamesDF['VidGam'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9c3841f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Blend both dataframes into one, shuffle rows\n",
    "#For computational time, limiting to approximately 100,000 reviews\n",
    "Blend = [LuxuryBeautyDF,VideoGamesDF]\n",
    "BlendDF = pd.concat(Blend)\n",
    "BlendDF = BlendDF.sample(frac = 0.1).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f300ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add column with Date from converted Unix time. Unfortunately results does not give time.\n",
    "BlendDF[\"Date\"] = pd.to_datetime(BlendDF[\"unixReviewTime\"], unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e86c131",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create binary rating column: 0 (negative = 1-2), 1 (positive = 3-5)\n",
    "#Binning decision came from running tests against validation data\n",
    "conditions = [\n",
    "    (BlendDF[\"overall\"] > 2),\n",
    "    (BlendDF[\"overall\"] < 3)\n",
    "    ]\n",
    "values = [1, 0]\n",
    "BlendDF['BinaryRating'] = np.select(conditions, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06d5d39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create column of review text with all lowercase, no punctuation, and no stopwords\n",
    "nan_value = float(\"NaN\") #Create na variable for blanks\n",
    "BlendDF[\"reviewText\"].replace(\"\", nan_value, inplace=True) #Replace blanks with na variable\n",
    "BlendDF.dropna(subset = [\"reviewText\"], inplace=True) #Drop all rows with na review text\n",
    "BlendDF[\"ReviewNoFiller\"] = BlendDF[\"reviewText\"].str.replace('[^\\w\\s]','',regex=True) #Create column with review text with no punctuation\n",
    "BlendDF[\"ReviewNoFiller\"] = BlendDF[\"ReviewNoFiller\"].str.lower() #Make all words lowercase\n",
    "stopwords = stopwords.words('english') #Create stopwords variable\n",
    "BlendDF[\"ReviewNoFiller\"] = BlendDF[\"ReviewNoFiller\"].apply(lambda x: ' '.join([word for word in x.split() if word not in (stopwords)])) #Remove stop words\n",
    "BlendDF[\"ReviewNoFiller\"].replace(\"\", nan_value, inplace=True,regex=True) #Replace blanks with na\n",
    "BlendDF.dropna(subset = [\"ReviewNoFiller\"], inplace=True) #Drop all rows with na review text, reset indices\n",
    "BlendDF = BlendDF.sample(frac = 1).reset_index() #Randomize resulting dataframe and reset indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5a326eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Insert columns with tokenized review and summary\n",
    "BlendDF[\"ReviewToken\"] = BlendDF.apply(lambda row: word_tokenize(row[\"ReviewNoFiller\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d93aefb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lemmatize all reviews and summaries, rejoin the strings\n",
    "WNL = WordNetLemmatizer()\n",
    "def lemmatize_text(text):\n",
    "    return [WNL.lemmatize(w) for w in text]\n",
    "BlendDF['ReviewToken'] = BlendDF.ReviewToken.apply(lemmatize_text)\n",
    "BlendDF['ReviewLemma'] = BlendDF['ReviewToken'].apply(' '.join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0731140f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5    68078\n",
      "4    16487\n",
      "3     8970\n",
      "1     8259\n",
      "2     5239\n",
      "Name: overall, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Print out distribution of resulting review ratings\n",
    "print(BlendDF['overall'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "987d03cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Insert column with VADER sentiment analysis compound score of full review text, scale numbers from 1 to 5\n",
    "vader = SentimentIntensityAnalyzer()\n",
    "BlendDF[\"VaderCompound\"] = [vader.polarity_scores(x)['compound'] for x in BlendDF['reviewText']]\n",
    "scaler = MinMaxScaler(feature_range=(1,5))\n",
    "BlendDF[\"VaderCompound\"] = scaler.fit_transform(BlendDF[\"VaderCompound\"].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a9adb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Insert column with review word count\n",
    "BlendDF[\"WordCount\"] = BlendDF[\"ReviewToken\"].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78cfd107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    107033.000000\n",
      "mean         40.980688\n",
      "std          88.418301\n",
      "min           1.000000\n",
      "25%           5.000000\n",
      "50%          15.000000\n",
      "75%          38.000000\n",
      "max        3112.000000\n",
      "Name: WordCount, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#What does word count distribution look like? Need visualization to decide how to bin data. Also look at descriptive statistics.\n",
    "WordHist = BlendDF.hist(column = 'WordCount', bins=300)\n",
    "plt.xlim([0,150])\n",
    "print(BlendDF[\"WordCount\"].describe()) #25% is 6 or less, 25% is 29 words or more, will bin accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb48f5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create column categorizing review word count as short (1) or not (0)\n",
    "conditions = [\n",
    "    (BlendDF[\"WordCount\"] < 7),\n",
    "    (BlendDF[\"WordCount\"] > 6)\n",
    "    ]\n",
    "values = [1,0]\n",
    "BlendDF['Short'] = np.select(conditions, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31aa1461",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create column categorizing review word count as long (1) or not (0)\n",
    "conditions = [\n",
    "    (BlendDF[\"WordCount\"] > 28),\n",
    "    (BlendDF[\"WordCount\"] < 29)\n",
    "    ]\n",
    "values = [1,0]\n",
    "BlendDF['Long'] = np.select(conditions, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4fa7d1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create column categorizing reviewer as verified (1) or not (0)\n",
    "conditions = [\n",
    "    (BlendDF['verified'] == True),\n",
    "    (BlendDF['verified'] == False)\n",
    "    ]\n",
    "values = [1, 0]\n",
    "BlendDF['Verified'] = np.select(conditions, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a33de467",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create binary column if the reviewer uploaded an image (1) or did not (0)\n",
    "conditions = [\n",
    "    (pd.notnull(BlendDF['image'])),\n",
    "    (pd.isnull(BlendDF['image']))\n",
    "    ]\n",
    "values = [1, 0]\n",
    "BlendDF['IsImage'] = np.select(conditions, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a53b258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level_0                    int64\n",
      "index                      int64\n",
      "overall                    int64\n",
      "vote                      object\n",
      "verified                    bool\n",
      "reviewTime                object\n",
      "reviewerID                object\n",
      "asin                      object\n",
      "reviewerName              object\n",
      "reviewText                object\n",
      "summary                   object\n",
      "unixReviewTime             int64\n",
      "style                     object\n",
      "image                     object\n",
      "LuxBea                     int64\n",
      "VidGam                     int64\n",
      "Date              datetime64[ns]\n",
      "BinaryRating               int32\n",
      "ReviewNoFiller            object\n",
      "ReviewToken               object\n",
      "ReviewLemma               object\n",
      "VaderCompound            float64\n",
      "WordCount                  int64\n",
      "Short                      int32\n",
      "Long                       int32\n",
      "Verified                   int32\n",
      "IsImage                    int32\n",
      "dtype: object \n",
      "\n",
      "level_0                    int64\n",
      "index                      int64\n",
      "overall                    int64\n",
      "vote                       int32\n",
      "verified                    bool\n",
      "reviewTime                object\n",
      "reviewerID                object\n",
      "asin                      object\n",
      "reviewerName              object\n",
      "reviewText                object\n",
      "summary                   object\n",
      "unixReviewTime             int64\n",
      "style                     object\n",
      "image                     object\n",
      "LuxBea                     int64\n",
      "VidGam                     int64\n",
      "Date              datetime64[ns]\n",
      "BinaryRating               int32\n",
      "ReviewNoFiller            object\n",
      "ReviewToken               object\n",
      "ReviewLemma               object\n",
      "VaderCompound            float64\n",
      "WordCount                  int64\n",
      "Short                      int32\n",
      "Long                       int32\n",
      "Verified                   int32\n",
      "IsImage                    int32\n",
      "dtype: object \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Adjust vote column to allow for analysis\n",
    "print(BlendDF.dtypes,'\\n')\n",
    "BlendDF['vote'] = BlendDF['vote'].str.replace('[^\\w\\s]','',regex=True) #Remove all punctuation from strings\n",
    "BlendDF['vote'].replace('', '0', inplace=True) #Replace blanks with 0\n",
    "BlendDF['vote'] = BlendDF['vote'].fillna('0') # Replace na values with 0\n",
    "BlendDF['vote'] = BlendDF['vote'].astype({'vote': 'int32'})\n",
    "print(BlendDF.dtypes,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8dc3a57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read into five emotions lexicon, convert into five dictionaries\n",
    "WarrinerWords = pd.read_csv(\"Warriner_BE.txt\", sep='\\t')\n",
    "JoyDict = dict(zip(WarrinerWords.Word, WarrinerWords.Joy))\n",
    "AngerDict = dict(zip(WarrinerWords.Word, WarrinerWords.Anger))\n",
    "SadnessDict = dict(zip(WarrinerWords.Word, WarrinerWords.Sadness))\n",
    "FearDict = dict(zip(WarrinerWords.Word, WarrinerWords.Fear))\n",
    "DisgustDict = dict(zip(WarrinerWords.Word, WarrinerWords.Disgust))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a750a7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create columns for five emotions, initialize all of them at zero\n",
    "BlendDF['Joy'] = 0.0\n",
    "BlendDF['Anger'] = 0.0\n",
    "BlendDF['Sadness'] = 0.0\n",
    "BlendDF['Fear'] = 0.0\n",
    "BlendDF['Disgust'] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6354b54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iterate through all lists of words, assigning them scores for all emotions\n",
    "for index, row in BlendDF.iterrows():\n",
    "    for word in row['ReviewToken']:\n",
    "        BlendDF.at[index,'Joy'] += JoyDict.get(word,0)\n",
    "        BlendDF.at[index,'Anger'] += AngerDict.get(word,0)\n",
    "        BlendDF.at[index,'Sadness'] += SadnessDict.get(word,0)\n",
    "        BlendDF.at[index,'Fear'] += FearDict.get(word,0)\n",
    "        BlendDF.at[index,'Disgust'] += DisgustDict.get(word,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d61dbe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReviewLemma\n",
      "VaderCompound\n",
      "Short\n",
      "Verified\n",
      "Long\n",
      "IsImage\n",
      "WordCount\n",
      "vote\n",
      "LuxBea\n",
      "VidGam\n",
      "Joy\n",
      "Anger\n",
      "Sadness\n",
      "Fear\n",
      "Disgust\n",
      "overall\n",
      "BinaryRating\n",
      "                                         ReviewLemma  VaderCompound  Short  \\\n",
      "0  play really good son d stolen played everyday ...       4.051153      0   \n",
      "1  worked better instruction said would kid love ...       4.509175      0   \n",
      "2  sold elsewhere 10 le received quick via prime ...       4.171759      0   \n",
      "3                        great product great service       4.717586      1   \n",
      "4  game thing liked snes version closely related ...       4.275564      0   \n",
      "\n",
      "   Verified  Long  IsImage  WordCount  vote  LuxBea  VidGam      Joy    Anger  \\\n",
      "0         1     0        0         13     0       0       1  18.0942   7.4295   \n",
      "1         1     1        0         51     0       0       1  56.1813  35.1353   \n",
      "2         1     1        0         50     2       0       1  88.1742  43.5115   \n",
      "3         1     0        0          4     4       1       0  13.1484   4.8373   \n",
      "4         1     1        0         41     0       0       1  58.5344  30.2599   \n",
      "\n",
      "   Sadness     Fear  Disgust  overall  BinaryRating  \n",
      "0   7.6809   7.6556   7.2815        4             1  \n",
      "1  34.4961  35.3017  34.9173        5             1  \n",
      "2  44.1557  44.8278  42.5477        5             1  \n",
      "3   5.0432   5.0031   4.7328        5             1  \n",
      "4  30.1919  31.4301  29.4247        3             1  \n",
      "The number of rows in the data frame is: 107033\n"
     ]
    }
   ],
   "source": [
    "#Create data frame for analysis\n",
    "BlendDF = BlendDF[['ReviewLemma','VaderCompound','Short','Verified','Long','IsImage','WordCount','vote',\n",
    "                   'LuxBea','VidGam','Joy','Anger','Sadness','Fear','Disgust','overall','BinaryRating']]\n",
    "\n",
    "#Print some of the dataframe to verify work\n",
    "pd.set_option('display.max_columns', None) #So as not to truncate output\n",
    "pd.set_option('display.max_rows', None) #So as not to truncate output\n",
    "for col in BlendDF.columns: #Print column names\n",
    "    print(col)\n",
    "print(BlendDF.head()) # Print first five entries in dataframe\n",
    "print(\"The number of rows in the data frame is:\", len(BlendDF.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "38316796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write final dataframe into csv\n",
    "BlendDF.to_csv(r'BlendedReviews.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9b90375b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Logistic Model Score for TF-IDF: 91.81 % \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.44      0.57      2630\n",
      "           1       0.93      0.99      0.95     18777\n",
      "\n",
      "    accuracy                           0.92     21407\n",
      "   macro avg       0.87      0.71      0.76     21407\n",
      "weighted avg       0.91      0.92      0.91     21407\n",
      " \n",
      "\n",
      "Binary SVM Score for TF-IDF: 92.26 % \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.50      0.61      2630\n",
      "           1       0.93      0.98      0.96     18777\n",
      "\n",
      "    accuracy                           0.92     21407\n",
      "   macro avg       0.86      0.74      0.78     21407\n",
      "weighted avg       0.92      0.92      0.91     21407\n",
      " \n",
      "\n",
      "K Nearest Neighbors Algorithm Model Score for TF-IDF:  88.62 % \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.17      0.27      2630\n",
      "           1       0.90      0.99      0.94     18777\n",
      "\n",
      "    accuracy                           0.89     21407\n",
      "   macro avg       0.76      0.58      0.61     21407\n",
      "weighted avg       0.86      0.89      0.86     21407\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "TF-IDF Approach\n",
    "First group of models are binary models predicting positive or negative rating\n",
    "\"\"\"\n",
    "\n",
    "#Implement TF-IDF for binary model\n",
    "tfidf = TfidfVectorizer(max_features=100000, ngram_range=(1,7), analyzer='char')\n",
    "X = tfidf.fit_transform(BlendDF['ReviewLemma'])\n",
    "Y = BlendDF['BinaryRating']\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=1) #Split into 80/20 train and test sets\n",
    "\n",
    "#Run binary logistic regression\n",
    "LR = linear_model.LogisticRegression(solver='lbfgs',max_iter=10000)\n",
    "LR.fit(X_train, Y_train)\n",
    "\n",
    "#Look at ability of model to predict test set\n",
    "LRScore = round((LR.score(X_test, Y_test))*100,2)\n",
    "print('Binary Logistic Model Score for TF-IDF:',LRScore,'%','\\n')\n",
    "Y_pred = LR.predict(X_test)\n",
    "print(classification_report(Y_test, Y_pred, zero_division=0), '\\n')\n",
    "\n",
    "#Run Binary SVM\n",
    "svclassifier = SVC(kernel='linear')\n",
    "svclassifier.fit(X_train, Y_train)\n",
    "\n",
    "#Look at ability of model to predict test set\n",
    "SVMScore = round((svclassifier.score(X_test, Y_test))*100,2)\n",
    "print('Binary SVM Score for TF-IDF:',SVMScore,'%','\\n')\n",
    "Y_pred = svclassifier.predict(X_test)\n",
    "print(classification_report(Y_test, Y_pred, zero_division=0), '\\n')\n",
    "\n",
    "#Run K Nearest Neighbors Algorithm\n",
    "KNN = KNeighborsClassifier(n_neighbors = 5)\n",
    "KNN.fit(X_train, Y_train)\n",
    "\n",
    "#Look at ability of model to predict test set\n",
    "KNNScore = round((KNN.score(X_test, Y_test))*100,2)\n",
    "print('K Nearest Neighbors Algorithm Model Score for TF-IDF: ',KNNScore,'%','\\n')\n",
    "Y_pred = KNN.predict(X_test)\n",
    "print(classification_report(Y_test, Y_pred, zero_division=0), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "56ce478d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Logistic Model Score for TF-IDF:  70.74 % \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.54      0.57      1626\n",
      "           2       0.38      0.07      0.12      1004\n",
      "           3       0.42      0.20      0.27      1830\n",
      "           4       0.46      0.24      0.32      3342\n",
      "           5       0.76      0.96      0.85     13605\n",
      "\n",
      "    accuracy                           0.71     21407\n",
      "   macro avg       0.53      0.40      0.43     21407\n",
      "weighted avg       0.65      0.71      0.66     21407\n",
      " \n",
      "\n",
      "Multiclass SVM Score is for TF-IDF:  70.82 % \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.58      0.59      1626\n",
      "           2       0.37      0.10      0.16      1004\n",
      "           3       0.40      0.20      0.27      1830\n",
      "           4       0.49      0.18      0.26      3342\n",
      "           5       0.75      0.97      0.85     13605\n",
      "\n",
      "    accuracy                           0.71     21407\n",
      "   macro avg       0.53      0.41      0.43     21407\n",
      "weighted avg       0.65      0.71      0.65     21407\n",
      " \n",
      "\n",
      "K Nearest Neighbors Algorithm Model Score for TF-IDF:  63.1 % \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.17      0.26      1626\n",
      "           2       0.32      0.02      0.04      1004\n",
      "           3       0.20      0.08      0.11      1830\n",
      "           4       0.25      0.11      0.15      3342\n",
      "           5       0.68      0.93      0.79     13605\n",
      "\n",
      "    accuracy                           0.63     21407\n",
      "   macro avg       0.40      0.26      0.27     21407\n",
      "weighted avg       0.55      0.63      0.56     21407\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "TF-IDF Approach\n",
    "Second group of models are multiclass models for 1-5 rating\n",
    "\"\"\"\n",
    "#Implement TF-IDF for multiclass model\n",
    "tfidf = TfidfVectorizer(max_features=100000, ngram_range=(1,7), analyzer='char')\n",
    "X = tfidf.fit_transform(BlendDF['ReviewLemma'])\n",
    "Y = BlendDF['overall']\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=1) #Split into 80/20 train and test sets\n",
    "\n",
    "#Run multinomial logistic regression\n",
    "MLR = linear_model.LogisticRegression(multi_class='multinomial', solver='lbfgs',max_iter=10000)\n",
    "MLR.fit(X_train, Y_train)\n",
    "\n",
    "#Look at ability of model to predict test set\n",
    "MLRScore = round((MLR.score(X_test, Y_test))*100,2)\n",
    "print('Multinomial Logistic Model Score for TF-IDF: ',MLRScore,'%','\\n')\n",
    "Y_pred = MLR.predict(X_test)\n",
    "print(classification_report(Y_test, Y_pred, zero_division=0), '\\n')\n",
    "\n",
    "#Run Multiclass SVM\n",
    "msvclassifier = SVC(kernel='linear')\n",
    "msvclassifier.fit(X_train, Y_train)\n",
    "\n",
    "#Look at ability of model to predict test set\n",
    "MSVMScore = round((msvclassifier.score(X_test, Y_test))*100,2)\n",
    "print('Multiclass SVM Score is for TF-IDF: ',MSVMScore,'%','\\n')\n",
    "Y_pred = msvclassifier.predict(X_test)\n",
    "print(classification_report(Y_test, Y_pred, zero_division=0), '\\n')\n",
    "\n",
    "#Run K Nearest Neighbors Algorithm\n",
    "KNN = KNeighborsClassifier(n_neighbors = 15)\n",
    "KNN.fit(X_train, Y_train)\n",
    "\n",
    "#Look at ability of model to predict test set\n",
    "KNNScore = round((KNN.score(X_test, Y_test))*100,2)\n",
    "print('K Nearest Neighbors Algorithm Model Score for TF-IDF: ',KNNScore,'%','\\n')\n",
    "Y_pred = KNN.predict(X_test)\n",
    "print(classification_report(Y_test, Y_pred, zero_division=0), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c14be7c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\18643\\AppData\\Local\\Temp/ipykernel_15168/2799700782.py:39: DeprecationWarning: Call to deprecated `docvecs` (The `docvecs` property has been renamed `dv`.).\n",
      "  vectors[i] = model.docvecs[prefix]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Logistic Model Score for Doc2Vec: 90.76 % \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.43      0.53      2630\n",
      "           1       0.92      0.97      0.95     18777\n",
      "\n",
      "    accuracy                           0.91     21407\n",
      "   macro avg       0.81      0.70      0.74     21407\n",
      "weighted avg       0.90      0.91      0.90     21407\n",
      " \n",
      "\n",
      "Binary SVM Score for Doc2Vec is: 90.92 % \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.39      0.51      2630\n",
      "           1       0.92      0.98      0.95     18777\n",
      "\n",
      "    accuracy                           0.91     21407\n",
      "   macro avg       0.84      0.69      0.73     21407\n",
      "weighted avg       0.90      0.91      0.90     21407\n",
      " \n",
      "\n",
      "K Nearest Neighbors Algorithm Model Score for Doc2Vec:  89.3 % \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.32      0.42      2630\n",
      "           1       0.91      0.97      0.94     18777\n",
      "\n",
      "    accuracy                           0.89     21407\n",
      "   macro avg       0.77      0.65      0.68     21407\n",
      "weighted avg       0.88      0.89      0.88     21407\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Doc2Vec Approach\n",
    "First group of models are binary models predicting positive or negative rating\n",
    "\"\"\"\n",
    "\n",
    "#Split into 80/20 train and test \n",
    "X = BlendDF['ReviewLemma']\n",
    "Y = BlendDF['BinaryRating']\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=1)\n",
    "\n",
    "#Function to label reviews train or test\n",
    "def label_reviews(review, label_type):\n",
    "    labeled = []\n",
    "    for i,v in enumerate(review):\n",
    "        label = label_type + '_' + str(i)\n",
    "        labeled.append(TaggedDocument(v.split(), [label]))\n",
    "    return labeled\n",
    "\n",
    "#Label training and test sets using function\n",
    "X_train = label_reviews(X_train, 'Train')\n",
    "X_test = label_reviews(X_test,'Test')\n",
    "AllData = X_train + X_test\n",
    "\n",
    "#Build BOW Doc2Vec model\n",
    "DBOWModel = Doc2Vec(dm=0, vector_size=300, negative=5, min_count=1, alpha=0.065, min_alpha=0.065)\n",
    "DBOWModel.build_vocab([x for x in AllData])\n",
    "\n",
    "#Iterate over data to train model\n",
    "for epoch in range(30):\n",
    "    DBOWModel.train(utils.shuffle([x for x in AllData]), total_examples=len(AllData), epochs=1)\n",
    "    DBOWModel.alpha -= 0.002\n",
    "    DBOWModel.min_alpha = DBOWModel.alpha\n",
    "\n",
    "#Create function to vectorize all reviews\n",
    "def get_vectors(model, corpus_size, vectors_size, vectors_type):\n",
    "    vectors = np.zeros((corpus_size, vectors_size))\n",
    "    for i in range(0, corpus_size):\n",
    "        prefix = vectors_type + '_' + str(i)\n",
    "        vectors[i] = model.docvecs[prefix]\n",
    "    return vectors\n",
    "\n",
    "#Vectorize training and testing data\n",
    "train_vectors_dbow = get_vectors(DBOWModel, len(X_train), 300, 'Train')\n",
    "test_vectors_dbow = get_vectors(DBOWModel, len(X_test), 300, 'Test')\n",
    "\n",
    "#Run binary logistic regression\n",
    "LR = linear_model.LogisticRegression(solver='lbfgs',max_iter=10000)\n",
    "LR = LR.fit(train_vectors_dbow, Y_train)\n",
    "\n",
    "#Look at ability of model to predict test set\n",
    "LRScore = round((LR.score(test_vectors_dbow, Y_test))*100,2)\n",
    "print('Binary Logistic Model Score for Doc2Vec:',LRScore,'%','\\n')\n",
    "Y_pred = LR.predict(test_vectors_dbow)\n",
    "print(classification_report(Y_test, Y_pred, zero_division=0), '\\n')\n",
    "\n",
    "#Run Binary SVM\n",
    "svclassifier = SVC(kernel='linear')\n",
    "svclassifier.fit(train_vectors_dbow, Y_train)\n",
    "\n",
    "#Look at ability of model to predict test set\n",
    "SVMScore = round((svclassifier.score(test_vectors_dbow, Y_test))*100,2)\n",
    "print('Binary SVM Score for Doc2Vec is:',SVMScore,'%','\\n')\n",
    "Y_pred = svclassifier.predict(test_vectors_dbow)\n",
    "print(classification_report(Y_test, Y_pred, zero_division=0), '\\n')\n",
    "\n",
    "#Run K Nearest Neighbors Algorithm\n",
    "KNN = KNeighborsClassifier(n_neighbors = 5)\n",
    "KNN.fit(train_vectors_dbow, Y_train)\n",
    "\n",
    "#Look at ability of model to predict test set\n",
    "KNNScore = round((KNN.score(test_vectors_dbow, Y_test))*100,2)\n",
    "print('K Nearest Neighbors Algorithm Model Score for Doc2Vec: ',KNNScore,'%','\\n')\n",
    "Y_pred = KNN.predict(test_vectors_dbow)\n",
    "print(classification_report(Y_test, Y_pred, zero_division=0), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7b51f93b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\18643\\AppData\\Local\\Temp/ipykernel_15168/2799700782.py:39: DeprecationWarning: Call to deprecated `docvecs` (The `docvecs` property has been renamed `dv`.).\n",
      "  vectors[i] = model.docvecs[prefix]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Logistic Model Score for Doc2Vec:  68.99 % \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.53      0.53      1626\n",
      "           2       0.30      0.07      0.12      1004\n",
      "           3       0.33      0.16      0.21      1830\n",
      "           4       0.46      0.21      0.29      3342\n",
      "           5       0.75      0.94      0.83     13605\n",
      "\n",
      "    accuracy                           0.69     21407\n",
      "   macro avg       0.48      0.38      0.40     21407\n",
      "weighted avg       0.63      0.69      0.64     21407\n",
      " \n",
      "\n",
      "Multiclass SVM Score is for Doc2Vec:  67.86 % \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.52      0.53      1626\n",
      "           2       0.30      0.07      0.11      1004\n",
      "           3       0.34      0.17      0.23      1830\n",
      "           4       0.24      0.00      0.00      3342\n",
      "           5       0.71      0.98      0.82     13605\n",
      "\n",
      "    accuracy                           0.68     21407\n",
      "   macro avg       0.43      0.35      0.34     21407\n",
      "weighted avg       0.57      0.68      0.59     21407\n",
      " \n",
      "\n",
      "K Nearest Neighbors Algorithm Model Score for Doc2Vec:  66.02 % \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.34      0.42      1626\n",
      "           2       0.28      0.02      0.03      1004\n",
      "           3       0.37      0.05      0.09      1830\n",
      "           4       0.35      0.02      0.04      3342\n",
      "           5       0.67      0.98      0.80     13605\n",
      "\n",
      "    accuracy                           0.66     21407\n",
      "   macro avg       0.44      0.28      0.27     21407\n",
      "weighted avg       0.57      0.66      0.56     21407\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Doc2Vec Approach\n",
    "Second group of models are multiclass models for 1-5 rating\n",
    "\"\"\"\n",
    "\n",
    "#Split into 80/20 train and test \n",
    "X = BlendDF['ReviewLemma']\n",
    "Y = BlendDF['overall']\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=1)\n",
    "\n",
    "#Label training and test sets using function\n",
    "X_train = label_reviews(X_train, 'Train')\n",
    "X_test = label_reviews(X_test,'Test')\n",
    "AllData = X_train + X_test\n",
    "\n",
    "#Build Doc2Vec model\n",
    "DBOWModel = Doc2Vec(dm=0, vector_size=300, negative=5, min_count=1, alpha=0.065, min_alpha=0.065)\n",
    "DBOWModel.build_vocab([x for x in AllData])\n",
    "\n",
    "#Iterate over data to train model\n",
    "for epoch in range(30):\n",
    "    DBOWModel.train(utils.shuffle([x for x in AllData]), total_examples=len(AllData), epochs=1)\n",
    "    DBOWModel.alpha -= 0.002\n",
    "    DBOWModel.min_alpha = DBOWModel.alpha\n",
    "\n",
    "#Vectorize training and testing data\n",
    "train_vectors_dbow = get_vectors(DBOWModel, len(X_train), 300, 'Train')\n",
    "test_vectors_dbow = get_vectors(DBOWModel, len(X_test), 300, 'Test')\n",
    "\n",
    "#Run multinomial logistic regression\n",
    "MLR = linear_model.LogisticRegression(multi_class='multinomial', solver='lbfgs',max_iter=10000)\n",
    "MLR.fit(train_vectors_dbow, Y_train)\n",
    "\n",
    "#Look at ability of model to predict test set\n",
    "MLRScore = round((MLR.score(test_vectors_dbow, Y_test))*100,2)\n",
    "print('Multinomial Logistic Model Score for Doc2Vec: ',MLRScore,'%','\\n')\n",
    "Y_pred = MLR.predict(test_vectors_dbow)\n",
    "print(classification_report(Y_test, Y_pred, zero_division=0), '\\n')\n",
    "\n",
    "#Run Multiclass SVM\n",
    "msvclassifier = SVC(kernel='linear')\n",
    "msvclassifier.fit(train_vectors_dbow, Y_train)\n",
    "\n",
    "#Look at ability of model to predict test set\n",
    "MSVMScore = round((msvclassifier.score(test_vectors_dbow, Y_test))*100,2)\n",
    "print('Multiclass SVM Score is for Doc2Vec: ',MSVMScore,'%','\\n')\n",
    "Y_pred = msvclassifier.predict(test_vectors_dbow)\n",
    "print(classification_report(Y_test, Y_pred, zero_division=0), '\\n')\n",
    "\n",
    "#Run K Nearest Neighbors Algorithm\n",
    "KNN = KNeighborsClassifier(n_neighbors = 15)\n",
    "KNN.fit(train_vectors_dbow, Y_train)\n",
    "\n",
    "#Look at ability of model to predict test set\n",
    "KNNScore = round((KNN.score(test_vectors_dbow, Y_test))*100,2)\n",
    "print('K Nearest Neighbors Algorithm Model Score for Doc2Vec: ',KNNScore,'%','\\n')\n",
    "Y_pred = KNN.predict(test_vectors_dbow)\n",
    "print(classification_report(Y_test, Y_pred, zero_division=0), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "36fb7069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Logistic Intercept is: [-2.20475949] \n",
      "\n",
      "Binary Logistic Coefficients are: [[ 1.04310648  0.64922883  0.18505858 -0.15719426 -0.88483446]] \n",
      "\n",
      "Binary Logistic Model Score for VADER Score: 87.93 % \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.25      0.34      2630\n",
      "           1       0.90      0.97      0.93     18777\n",
      "\n",
      "    accuracy                           0.88     21407\n",
      "   macro avg       0.71      0.61      0.64     21407\n",
      "weighted avg       0.86      0.88      0.86     21407\n",
      " \n",
      "\n",
      "Binary SVM Score for VADER Score: 87.71 % \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      2630\n",
      "           1       0.88      1.00      0.93     18777\n",
      "\n",
      "    accuracy                           0.88     21407\n",
      "   macro avg       0.44      0.50      0.47     21407\n",
      "weighted avg       0.77      0.88      0.82     21407\n",
      " \n",
      "\n",
      "Binary Naive Bayes Classifier Score for VADER Score: 87.32 % \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.33      0.39      2630\n",
      "           1       0.91      0.95      0.93     18777\n",
      "\n",
      "    accuracy                           0.87     21407\n",
      "   macro avg       0.69      0.64      0.66     21407\n",
      "weighted avg       0.86      0.87      0.86     21407\n",
      " \n",
      "\n",
      "Stacked ensemble model score for VADER Score:  87.48 % \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.22      0.30      2630\n",
      "           1       0.90      0.97      0.93     18777\n",
      "\n",
      "    accuracy                           0.87     21407\n",
      "   macro avg       0.69      0.59      0.62     21407\n",
      "weighted avg       0.85      0.87      0.85     21407\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "VADER Score\n",
    "First group of models are binary models predicting positive or negative rating\n",
    "\"\"\"\n",
    "\n",
    "#Split data into training and test sets with a 80/20 split for all binary models\n",
    "X = BlendDF[['VaderCompound','Short','Verified','Long','IsImage']] #set independent variables for regression\n",
    "Y = BlendDF['BinaryRating'] #set dependent variable for regression\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=1) #Split into 80/20 train and test sets\n",
    "\n",
    "#Run binary logistic regression\n",
    "LR = linear_model.LogisticRegression(solver='lbfgs',max_iter=10000)\n",
    "LR.fit(X_train, Y_train)\n",
    "print('Binary Logistic Intercept is:', LR.intercept_, '\\n')\n",
    "print('Binary Logistic Coefficients are:', LR.coef_, '\\n')\n",
    "\n",
    "#Look at ability of model to predict test set\n",
    "LRScore = round((LR.score(X_test, Y_test))*100,2)\n",
    "print('Binary Logistic Model Score for VADER Score:',LRScore,'%','\\n')\n",
    "Y_pred = LR.predict(X_test)\n",
    "print(classification_report(Y_test, Y_pred, zero_division=0), '\\n')\n",
    "\n",
    "#Run Binary SVM\n",
    "svclassifier = SVC(kernel='linear')\n",
    "svclassifier.fit(X_train, Y_train)\n",
    "\n",
    "#Look at ability of model to predict test set\n",
    "SVMScore = round((svclassifier.score(X_test, Y_test))*100,2)\n",
    "print('Binary SVM Score for VADER Score:',SVMScore,'%','\\n')\n",
    "Y_pred = svclassifier.predict(X_test)\n",
    "print(classification_report(Y_test, Y_pred, zero_division=0), '\\n')\n",
    "\n",
    "#Run Naive Bayes Classifier\n",
    "NB = GaussianNB()\n",
    "NB.fit(X_train, Y_train)\n",
    "\n",
    "#Look at ability of model to predict test set\n",
    "NBScore = round((NB.score(X_test, Y_test))*100,2)\n",
    "print('Binary Naive Bayes Classifier Score for VADER Score:',NBScore,'%','\\n')\n",
    "Y_pred = NB.predict(X_test)\n",
    "print(classification_report(Y_test, Y_pred, zero_division=0), '\\n')\n",
    "\n",
    "#Implement stacked ensemble model\n",
    "Estimators = [('NB',NB), ('SVM',svclassifier)]\n",
    "StackedModel = StackingClassifier (estimators = Estimators, final_estimator = linear_model.LogisticRegression(solver='lbfgs',max_iter=10000))\n",
    "StackedModel.fit(X_train, Y_train)\n",
    "\n",
    "#Look at ability of stacked ensemble model to predict test set\n",
    "StackScore = round((StackedModel.score(X_test, Y_test))*100,2)\n",
    "print('Stacked ensemble model score for VADER Score: ',StackScore,'%','\\n')\n",
    "Y_pred = StackedModel.predict(X_test)\n",
    "print(classification_report(Y_test, Y_pred, zero_division=0), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9a4e44ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Logistic Model Score for VADER Score:  64.63 % \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.34      0.37      0.35      1626\n",
      "           2       0.00      0.00      0.00      1004\n",
      "           3       0.16      0.01      0.01      1830\n",
      "           4       0.26      0.00      0.01      3342\n",
      "           5       0.68      0.97      0.80     13605\n",
      "\n",
      "    accuracy                           0.65     21407\n",
      "   macro avg       0.29      0.27      0.23     21407\n",
      "weighted avg       0.51      0.65      0.54     21407\n",
      " \n",
      "\n",
      "Multiclass SVM Score is for VADER Score:  64.66 % \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.34      0.34      0.34      1626\n",
      "           2       0.00      0.00      0.00      1004\n",
      "           3       0.00      0.00      0.00      1830\n",
      "           4       0.00      0.00      0.00      3342\n",
      "           5       0.67      0.98      0.80     13605\n",
      "\n",
      "    accuracy                           0.65     21407\n",
      "   macro avg       0.20      0.26      0.23     21407\n",
      "weighted avg       0.45      0.65      0.53     21407\n",
      " \n",
      "\n",
      "K Nearest Neighbors Algorithm Model Score for VADER Score:  63.47 % \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.36      0.37      0.36      1626\n",
      "           2       0.16      0.04      0.06      1004\n",
      "           3       0.19      0.06      0.09      1830\n",
      "           4       0.25      0.07      0.11      3342\n",
      "           5       0.70      0.93      0.80     13605\n",
      "\n",
      "    accuracy                           0.63     21407\n",
      "   macro avg       0.33      0.29      0.28     21407\n",
      "weighted avg       0.54      0.63      0.56     21407\n",
      " \n",
      "\n",
      "Random Forest Classifier Model Score for VADER Score:  60.76 % \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.35      0.29      0.31      1626\n",
      "           2       0.13      0.08      0.10      1004\n",
      "           3       0.16      0.08      0.11      1830\n",
      "           4       0.22      0.11      0.14      3342\n",
      "           5       0.71      0.88      0.78     13605\n",
      "\n",
      "    accuracy                           0.61     21407\n",
      "   macro avg       0.31      0.29      0.29     21407\n",
      "weighted avg       0.53      0.61      0.56     21407\n",
      " \n",
      "\n",
      "Stacked ensemble model score for VADER Score:  64.89 % \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.35      0.42      0.38      1626\n",
      "           2       0.00      0.00      0.00      1004\n",
      "           3       0.17      0.00      0.01      1830\n",
      "           4       0.34      0.00      0.01      3342\n",
      "           5       0.68      0.97      0.80     13605\n",
      "\n",
      "    accuracy                           0.65     21407\n",
      "   macro avg       0.31      0.28      0.24     21407\n",
      "weighted avg       0.53      0.65      0.54     21407\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "VADER Score\n",
    "Second group of models are multiclass models for 1-5 rating\n",
    "\"\"\"\n",
    "#Split data into training and test sets with a 80/20 split for multiclass models\n",
    "X = BlendDF[['VaderCompound','Short','Verified','Long','IsImage']] #set independent variables for regression\n",
    "Y = BlendDF['overall'] #set dependent variable for regression\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=1) #Split into 80/20 train and test sets\n",
    "\n",
    "#Run multinomial logistic regression\n",
    "MLR = linear_model.LogisticRegression(multi_class='multinomial', solver='lbfgs',max_iter=10000)\n",
    "MLR.fit(X_train, Y_train)\n",
    "\n",
    "#Look at ability of model to predict test set\n",
    "MLRScore = round((MLR.score(X_test, Y_test))*100,2)\n",
    "print('Multinomial Logistic Model Score for VADER Score: ',MLRScore,'%','\\n')\n",
    "Y_pred = MLR.predict(X_test)\n",
    "print(classification_report(Y_test, Y_pred, zero_division=0), '\\n')\n",
    "\n",
    "#Run Multiclass SVM\n",
    "msvclassifier = SVC(kernel='linear')\n",
    "msvclassifier.fit(X_train, Y_train)\n",
    "\n",
    "#Look at ability of model to predict test set\n",
    "MSVMScore = round((msvclassifier.score(X_test, Y_test))*100,2)\n",
    "print('Multiclass SVM Score is for VADER Score: ',MSVMScore,'%','\\n')\n",
    "Y_pred = msvclassifier.predict(X_test)\n",
    "print(classification_report(Y_test, Y_pred, zero_division=0), '\\n')\n",
    "\n",
    "#Run K Nearest Neighbors Algorithm\n",
    "KNN = KNeighborsClassifier(n_neighbors = 15)\n",
    "KNN.fit(X_train, Y_train)\n",
    "\n",
    "#Look at ability of model to predict test set\n",
    "KNNScore = round((KNN.score(X_test, Y_test))*100,2)\n",
    "print('K Nearest Neighbors Algorithm Model Score for VADER Score: ',KNNScore,'%','\\n')\n",
    "Y_pred = KNN.predict(X_test)\n",
    "print(classification_report(Y_test, Y_pred, zero_division=0), '\\n')\n",
    "\n",
    "#Run Random Forest Algorithm\n",
    "RF = RandomForestClassifier(n_estimators=5, random_state=0)\n",
    "RF.fit(X_train, Y_train)\n",
    "\n",
    "#Look at ability of model to predict test set\n",
    "RFScore = round((RF.score(X_test, Y_test))*100,2)\n",
    "print('Random Forest Classifier Model Score for VADER Score: ',RFScore,'%','\\n')\n",
    "Y_pred = RF.predict(X_test)\n",
    "print(classification_report(Y_test, Y_pred, zero_division=0), '\\n')\n",
    "\n",
    "#Implement stacked ensemble model\n",
    "Estimators = [('KNN',KNN), ('SVM',msvclassifier)]\n",
    "StackedModel = StackingClassifier (estimators = Estimators, final_estimator = linear_model.LogisticRegression(multi_class='multinomial', solver='lbfgs',max_iter=10000))\n",
    "StackedModel.fit(X_train, Y_train)\n",
    "\n",
    "#Look at ability of stacked ensemble model to predict test set\n",
    "StackScore = round((StackedModel.score(X_test, Y_test))*100,2)\n",
    "print('Stacked ensemble model score for VADER Score: ',StackScore,'%','\\n')\n",
    "Y_pred = StackedModel.predict(X_test)\n",
    "print(classification_report(Y_test, Y_pred, zero_division=0), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "30d94258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Classifier Score is for Five Emotions Model:  87.29 % \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.02      0.04      2630\n",
      "           1       0.88      0.99      0.93     18777\n",
      "\n",
      "    accuracy                           0.87     21407\n",
      "   macro avg       0.58      0.51      0.49     21407\n",
      "weighted avg       0.81      0.87      0.82     21407\n",
      " \n",
      "\n",
      "Binary Logistic Model Score for Five Emotions Model:  87.57 % \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.03      0.06      2630\n",
      "           1       0.88      0.99      0.93     18777\n",
      "\n",
      "    accuracy                           0.88     21407\n",
      "   macro avg       0.65      0.51      0.50     21407\n",
      "weighted avg       0.82      0.88      0.83     21407\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Five Emotions Approach and other variables approach\n",
    "First group of models are binary models predicting positive or negative rating\n",
    "SVM Models have been excluded due to high number of continuous variables makes processing power/time overwhelming\n",
    "\"\"\"\n",
    "\n",
    "#Split data into training and test sets with a 80/20 split for all binary models\n",
    "#Based on the very low coefficients for both WordCount and vote, these variables were left out of the models.\n",
    "X = BlendDF[['Joy','Anger','Sadness','Fear','Disgust','Short','Verified','Long','IsImage']] #set independent variables for regression\n",
    "Y = BlendDF['BinaryRating'] #set dependent variable for regression\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=1) #Split into 80/20 train and test sets\n",
    "\n",
    "#Run Naive Bayes Classifier\n",
    "NB = GaussianNB()\n",
    "NB.fit(X_train, Y_train)\n",
    "\n",
    "#Look at ability of model to predict test set\n",
    "NBScore = round((NB.score(X_test, Y_test))*100,2)\n",
    "print('Naive Bayes Classifier Score is for Five Emotions Model: ',NBScore,'%','\\n')\n",
    "Y_pred = NB.predict(X_test)\n",
    "print(classification_report(Y_test, Y_pred, zero_division=0), '\\n')\n",
    "\n",
    "#Run binary logistic regression\n",
    "LR = linear_model.LogisticRegression(solver='lbfgs',max_iter=10000)\n",
    "LR.fit(X_train, Y_train)\n",
    "\n",
    "#Look at ability of model to predict test set\n",
    "LRScore = round((LR.score(X_test, Y_test))*100,2)\n",
    "print('Binary Logistic Model Score for Five Emotions Model: ',LRScore,'%','\\n')\n",
    "Y_pred = LR.predict(X_test)\n",
    "print(classification_report(Y_test, Y_pred, zero_division=0), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b3b86c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Logistic Model Score for Five Emotions Model:  63.47 % \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.24      0.05      0.09      1626\n",
      "           2       0.29      0.00      0.00      1004\n",
      "           3       0.22      0.00      0.01      1830\n",
      "           4       0.34      0.02      0.04      3342\n",
      "           5       0.64      0.99      0.78     13605\n",
      "\n",
      "    accuracy                           0.63     21407\n",
      "   macro avg       0.35      0.21      0.18     21407\n",
      "weighted avg       0.51      0.63      0.51     21407\n",
      " \n",
      "\n",
      "K Nearest Neighbors Algorithm Model Score for Five Emotions Model:  62.18 % \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.30      0.15      0.20      1626\n",
      "           2       0.16      0.02      0.03      1004\n",
      "           3       0.15      0.03      0.04      1830\n",
      "           4       0.26      0.08      0.12      3342\n",
      "           5       0.66      0.94      0.78     13605\n",
      "\n",
      "    accuracy                           0.62     21407\n",
      "   macro avg       0.31      0.24      0.23     21407\n",
      "weighted avg       0.51      0.62      0.53     21407\n",
      " \n",
      "\n",
      "Random Forest Classifier Model Score for Five Emotions Model:  54.8 % \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.22      0.21      0.22      1626\n",
      "           2       0.10      0.07      0.08      1004\n",
      "           3       0.14      0.10      0.12      1830\n",
      "           4       0.20      0.15      0.17      3342\n",
      "           5       0.69      0.78      0.73     13605\n",
      "\n",
      "    accuracy                           0.55     21407\n",
      "   macro avg       0.27      0.26      0.27     21407\n",
      "weighted avg       0.51      0.55      0.52     21407\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Five Emotions Approach and other variables approach\n",
    "Second group of models are multiclass models for 1-5 rating\n",
    "SVM Models have been excluded due to high number of continuous variables makes processing power/time overwhelming\n",
    "\"\"\"\n",
    "\n",
    "#Split data into training and test sets with a 80/20 split for multiclass models\n",
    "#Based on the very low coefficients for both WordCount, vote and categories, these variables were left out of the models.\n",
    "X = BlendDF[['Joy','Anger','Sadness','Fear','Disgust','Short','Verified','Long','IsImage']] #set independent variables for regression\n",
    "Y = BlendDF['overall'] #set dependent variable for regression\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=1) #Split into 80/20 train and test sets\n",
    "\n",
    "#Run multinomial logistic regression\n",
    "MLR = linear_model.LogisticRegression(multi_class='multinomial', solver='lbfgs',max_iter=10000)\n",
    "MLR.fit(X_train, Y_train)\n",
    "\n",
    "#Look at ability of model to predict test set\n",
    "MLRScore = round((MLR.score(X_test, Y_test))*100,2)\n",
    "print('Multinomial Logistic Model Score for Five Emotions Model: ',MLRScore,'%','\\n')\n",
    "Y_pred = MLR.predict(X_test)\n",
    "print(classification_report(Y_test, Y_pred, zero_division=0), '\\n')\n",
    "\n",
    "#Run K Nearest Neighbors Algorithm\n",
    "KNN = KNeighborsClassifier(n_neighbors = 15)\n",
    "KNN.fit(X_train, Y_train)\n",
    "\n",
    "#Look at ability of model to predict test set\n",
    "KNNScore = round((KNN.score(X_test, Y_test))*100,2)\n",
    "print('K Nearest Neighbors Algorithm Model Score for Five Emotions Model: ',KNNScore,'%','\\n')\n",
    "Y_pred = KNN.predict(X_test)\n",
    "print(classification_report(Y_test, Y_pred, zero_division=0), '\\n')\n",
    "\n",
    "#Run Random Forest Algorithm\n",
    "RF = RandomForestClassifier(n_estimators=5, random_state=0)\n",
    "RF.fit(X_train, Y_train)\n",
    "\n",
    "#Look at ability of model to predict test set\n",
    "RFScore = round((RF.score(X_test, Y_test))*100,2)\n",
    "print('Random Forest Classifier Model Score for Five Emotions Model: ',RFScore,'%','\\n')\n",
    "Y_pred = RF.predict(X_test)\n",
    "print(classification_report(Y_test, Y_pred, zero_division=0), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "62a03bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:37:56\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Print out run times to decide how big of a data set to use\n",
    "\"\"\"\n",
    "\n",
    "ElapsedSeconds = time.time() - StartTime\n",
    "def convert(seconds):\n",
    "    seconds = seconds % (24 * 3600)\n",
    "    hour = seconds // 3600\n",
    "    seconds %= 3600\n",
    "    minutes = seconds // 60\n",
    "    seconds %= 60\n",
    "\n",
    "    return \"%d:%02d:%02d\" % (hour, minutes, seconds)\n",
    "print(convert(ElapsedSeconds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
